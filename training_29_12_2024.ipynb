{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a training example for paule\n",
    "It was created an the 29.12.2025. It is supposed to give you an idea how to train a model with paule. \n",
    "\n",
    "\n",
    "\n",
    "As the final output create_vtl_corpus generates a pandas.DataFrame with the following columns:\n",
    "\n",
    "    file_name : name of the mp3 file in the common voice corpus\n",
    "\n",
    "    label : word type, i. e. type of the word in terms of graphemic transcription\n",
    "\n",
    "    lexical_word : word as it was writen in the transcript\n",
    "\n",
    "    word_position : postion of the word type in the sentence\n",
    "\n",
    "    sentence : transcription of the full sentence\n",
    "\n",
    "    wav_recording : spliced out audio as mono audio signal\n",
    "\n",
    "    sr_recording : sampling rate of the recording\n",
    "\n",
    "    sampa_phones : list of phones in sampa notation\n",
    "\n",
    "    mfa_phones : list of phones in MFA notation\n",
    "\n",
    "    phone_durations : list of durations of the phones\n",
    "\n",
    "    vector : fastText vector embedding for the word_type\n",
    "\n",
    "    cp_norm : cp-trajectories of the segment-based synthesis\n",
    "\n",
    "    client_id : client_ids of multiple workers in multiprocessing\n",
    "\n",
    "The following columns are added, even if they can be generated out of the entries we already have for convenience:\n",
    "\n",
    "    wav_synthesized : wave form as mono audio from the segment-based synthesis\n",
    "\n",
    "    sr_synthesized : sampling rate for the mono audio from the segment-based synthesis\n",
    "\n",
    "    melspec_norm_recording : acoustic representation of human recording of the common voice corpus (log-mel spectrogram)\n",
    "\n",
    "    melspec_norm_synthesized : acoustic representation of the segment-based approach (log-mel spectrogram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data_path = \"../../../../mnt/Restricted/Corpora/CommonVoiceVTL/corpus_as_df_mp_folder_en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code in a seperate file. It might take a while so consider to use tmux or similar tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file_name', 'label', 'lexical_word', 'word_position', 'sentence',\n",
      "       'wav_recording', 'wav_synthesized', 'sr_recording', 'sr_synthesized',\n",
      "       'sampa_phones', 'mfa_phones', 'phone_durations', 'cp_norm', 'vector',\n",
      "       'client_id'],\n",
      "      dtype='object')\n",
      "Processed 1 files\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# First we need to split the data between validation,test and traning data.\n",
    "# For that we need to generate a comprehensive list of all the words\n",
    "\n",
    "words = Counter()\n",
    "i = 0\n",
    "for files in os.listdir(data_path):\n",
    "    if files.endswith(\".pkl\"):\n",
    "        data = pd.read_pickle(os.path.join(data_path,files))\n",
    "        print(data.columns)\n",
    "        for word in list(data[\"label\"]):\n",
    "            words[word] += 1\n",
    "    i += 1\n",
    "    print(f\"Processed {i} files\")\n",
    "print(\"Done\")\n",
    "\n",
    "words\n",
    "pickle.dump(words,open(\"words.pkl\",\"wb\"))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split the data in validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pickle.load(\"words.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
